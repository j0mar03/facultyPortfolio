## 1) Study ID and Citation

- Study ID: `S[ ]`
- Full citation (APA): Reyes, A. G. F., Paraleon, C. N. A., Bibera, R. V. V., Garcia, S. J. E. B., & Estrella, N. E. (2023). FEDesk: A Web and Mobile Document Management System for the University of Santo Tomas Office for Faculty Evaluation and Development. In _ASSE '23: Proceedings of the 2023 4th Asia Service Sciences and Software Engineering Conference_ (pp. 1-11). Association for Computing Machinery.
- DOI/URL: https://doi.org/10.1145/3634814.3634823
- Database source: `ACM`
- Year: 2023
- Country/Institution context: Philippines / University of Santo Tomas
- Evidence level: `Full text (PDF available)`

## 2) Study Focus

- Problem addressed (1-2 sentences): The Office for Faculty Evaluation and Development (OFED) experienced missed communications and delayed responses due to tracking incoming and outgoing documents manually via electronic mail, Google forms, and Excel spreadsheets. The shift to remote work during the pandemic accelerated the need for a centralized, digital document management system.
- Main objective/research question: To create a web and mobile document management system (FEDesk) providing an automated way to organize, track, access, and store documents for the OFED.
- Domain/context: `faculty evaluation / HEI management / document management`

## 3) System/Artifact Description

- System type: `hybrid` (web and mobile application)
- Target users/roles: Academic Unit, OFED Director, Assistant Director, Staff, Office of the Vice-Rector for Academic Affairs (OVRAA), and System Administrator.
- Core modules/features:
    - Central online repository with document search and retrieval.
    - Audit logs and real-time notification/tracking system.
    - User account management with two-factor authentication.
- Workflow scope covered:
    - Submission: Yes (web application allows academic units to submit necessary documents)
    - Review/approval: `NR` (tracks document status but does not specify a discrete approval logic flow)
    - Compliance checking: `NR`
    - Reporting/export: `NR` (allows searching but export features are only recommended for future iterations)
    - Role-based access: Yes (handles six user account types with varying privileges)

## 4) Methodology

- Research design: `DSR` (System development and testing)
- Development approach (if any): `Agile-Waterfall Hybrid Development Methodology`
- Evaluation design: Post-development testing combining unit testing, integration testing, non-functional requirements testing (security, performance, reliability, scalability, portability), and a User Acceptance Test (UAT).
- Study setting and duration: University of Santo Tomas (Office for Faculty Evaluation and Development); duration `NR`.

## 5) Participants and Data

- Unit of analysis: Individual target users (for UAT) and System modules (for technical testing).
- Sample size (n): 26 target users.
- Participant profile: End-users consisting of OFED staff, OVRAA, and academic unit representatives.
- Data sources:
    - `survey / system logs` (SUS questionnaire, automated test tools like Google Lighthouse, Uptime Robot, BlazeMeter).
- Inclusion/exclusion (if reported): `NR`

## 6) Instruments and Indicators

- Instruments used:
    - `SUS` (System Usability Scale)
    - `checklist / custom scripts` (Unit and Integration testing metrics, performance auditing tools)
- Main indicators/metrics:
    - Operational: `error rate` (success/failure of test cases), `processing time` (average response time in ms, uptime percentage)
    - Usability/acceptance: `SUS`
    - Governance: `traceability` (audit logs recording workflow status, history of document processes)
- Reliability reported? `No` (System hardware reliability was tested achieving 100% uptime, but statistical instrument reliability like Cronbach's alpha is `NR`).

## 7) Statistical Treatment

- Descriptive statistics used: Mean, percentages.
- Inferential statistics used: `NR`
- Effect size reported: `NR`
- If none, write: `NR`

## 8) Key Results (Numeric First)

- Result 1 (with value): The web application achieved an average response time of `mean = 279.95 ms` under load testing, and the performance test using Google Lighthouse yielded a `99%` highest percentage score.
- Result 2 (with value): The System Usability Scale (SUS) score calculated from 26 target users was `mean = 74.90 out of 100`, gaining a "good" adjective rating.
- Result 3 (with value): After debugging, the system achieved a `100%` success rate in both Unit Testing and Integration Testing across web and mobile platforms.
- Authors' main conclusion (1-2 sentences): FEDesk effectively met the project’s objectives by providing a centralized, automated document management system with high usability and technical reliability, ultimately improving collaboration and document tracking for the university's faculty evaluation processes.

## 9) Limitations (As Stated by Authors)

- Limitation 1: The mobile application is strictly for tracking and notification purposes only.
- Limitation 2: The filing of recommendations for academic staff can only be done individually, lacking a bulk submission feature.
- Limitation 3: Both the web and mobile applications cannot be used to natively create or edit documents.

## 10) Relevance to FPMS Study

- Directly useful SOP item(s): workflow improvement / usability / governance
- What gap remains after this study? The study successfully details a file tracking and routing system with strong auditability, but lacks built-in quality assurance compliance functions—specifically, it does not assess required-document completeness checks or provide granular review turnaround time tracking for faculty evaluation decisions.
- Transferability to my FPMS context: High
- Why? The domain perfectly overlaps with HEI faculty evaluation workflows (OFED/OVRAA). The identified users (Academic Units, Directors, Admin, Staff), the reliance on role-based access, the need for audit logs (traceability), and the measurement of usability (SUS) directly map to the core requirements of an FPMS. Even though it is a generalized document system rather than an exclusive portfolio builder, the architectural and operational metrics are highly applicable.

## 11) Matrix-Ready Summary (Copy to Chapter II)

- Authors (Year): Reyes, Paraleon, Bibera, Garcia, and Estrella (2023)
- Objective: To develop and evaluate a web and mobile document management system (FEDesk) to automate the organization, tracking, and storage of documents for a university's Office for Faculty Evaluation and Development.
- Method/system type: DSR (Agile-Waterfall Hybrid) / Web and Mobile Document Management System
- Data/sample: n = 26 target users (for SUS evaluation); systematic evaluation using automated test scripts.
- Metrics: SUS (usability), success rate of test cases (error rate), and system response time (processing time).
- Key finding: FEDesk achieved a solid SUS score of 74.90, resolved all bugs to hit a 100% test case success rate, and successfully automated role-based document tracking with audit logs for academic and administrative units.
- Limitation: The system does not support bulk submission of files or native document creation/editing, and its mobile app is restricted to notifications and tracking only.
- Gap relevant to FPMS: The study focuses on general file routing, storage, and traceability rather than strict evaluation compliance; it lacks mechanisms for required-document completeness checks and explicit review turnaround time metrics.