**Study ID/Title:** M. Senthil Murugan and Sree Kala T (2023) - "Large-scale data-driven financial risk management & analysis using machine learning strategies"

**Objective/Target variable:**

- **Objective:** To analyze and process large-scale datasets to predict loan defaults and their likelihood using machine learning models integrated with IoT deployment.
- **Target variable:** Loan Default / Likelihood of default (Binary/Probabilistic).

**Dataset:**

- **Source:** Large-scale online datasets gathered from FNCE5313. (Note: The feature names suggest a dataset similar to LendingClub).
- **Sample size (n):** "Large-scale" (Specific total $n$ NR, but Table 2 mentions "Higher access users" in batches of 1000–2600).
- **Features (count + key features):** 10 key features listed: `funded_amnt`, `emp_length`, `annual_inc`, `last_pymnt_amnt`, `mort_acc`, `int_rate`, `mo_sin_old_rev_tl_open`, `avg_cur_bal`, `acc_open_past_24 mths`, `num_sats`.
- **Class balance (counts or %):** NR

**Preprocessing:**

- **Missing values handling:** NR
- **Encoding/scaling:** NR
- **Feature selection (if any):**
    - **Information Gain:** Used to analyze which attributes were most important.
    - **Weight of Evidence (WOE):** Used to determine the predictive ability of independent variables.
- **Imbalance handling (SMOTE/class weights/undersampling/etc.):** NR

**Models compared:**

- Cluster-based K-Nearest Neighbor (KNN).
- Cluster-based Logistic Regression (LR).
- Cluster-based XG Boost.

**Validation design:**

- **Train/test split OR k-fold (k=?):**
    - **Split:** 30% Training, 70% Testing.
    - **Cross-validation:** The text mentions testing XG boost using "repeated k-fold cross-validation".
- **Any external validation?:** NR

**Metrics reported:**

- **Accuracy:** Yes (Range: 87%–98%).
- **Precision:** Yes (Mentioned as used, values NR in Table 2).
- **Recall:** Yes (Mentioned as used, values NR in Table 2).
- **F1-score:** Yes (Mentioned as used, values NR in Table 2).
- **ROC-AUC:** Yes (Mentioned as used, values NR in Table 2).
- **PR-AUC:** NR
- **Calibration (Brier/calibration curve):** Reliability plot and Brier score assessed.
- **Best model + best values:**
    - **KNN:** Achieved the highest accuracy range (97%–98%) and Mean Absolute Error (10%–13%).
    - **XG Boost:** Accuracy (91%–96%) and Mean Absolute Error (2%–7%).
    - _Note:_ The authors conclude that XG Boost and KNN are the proposed models.

**Statistical test/comparison:**

- Comparison with other techniques (FABC, IFABC, QFABC).

**Explainability:**

- **Feature importance/SHAP/LIME/etc.:** Information Gain and Weight of Evidence (WOE) used.
- **Top predictors:** NR (Specific top features not listed).

**Key findings (2-4 bullets):**

- **Model Performance:** KNN achieved the highest accuracy (97%–98%) compared to XG Boost (91%–96%) and Logistic Regression (87%–95%) in the reported metrics.
- **Wealth Management:** The investor’s wealth proportion measure of the proposed model ranges from 0.02 to 0.09.
- **Risk Strategy:** Applying a Value-at-Risk (VaR) strategy, the optimal consumption stability did not exceed 5% of the total investment wealth.

**Limitations (from paper):**

- **Computational Cost:** KNN can be computationally expensive and time-consuming if the training set is extensive.
- **Data Sensitivity:** Large-scale financial data contains sensitive personal information, requiring careful handling to prevent misuse.
- **Standard Model Flaws:** Traditional models often rely too heavily on past data and demographics, limiting their ability to seek new clients or provide dynamic early warnings.

**Deployment/implementation notes (if any):**

- **IoT Integration:** The study proposes deploying these machine learning models with Internet of Things (IoT) technology to get real-time data on assets.
- **Big Data Framework:** Utilizes Hadoop (HDFS, MapReduce) for processing large-scale datasets.