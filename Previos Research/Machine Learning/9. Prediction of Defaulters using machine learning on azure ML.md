**Study ID/Title:** Abhishek Shivanna and Dharma P Agrawal (2020) - "Prediction of Defaulters using Machine Learning on Azure ML"

**Objective/Target variable:**

- **Objective:** To build a model based on machine learning techniques that can accurately predict if a credit card customer will be a potential defaulter to aid credit risk management.
- **Target variable:** Default payment next month (Binary Classification).
    - **Classes:** 0 (Non-defaulter), 1 (Defaulter).

**Dataset:**

- **Source:** UCI Machine Learning Repository ("Default of credit card clients" dataset from a Taiwanese bank).
- **Sample size (n):** 30,000 observations.
- **Features (count + key features):** 25 attributes total (24 features). Key features include:
    - **Demographics:** Age, Gender, Marriage, Education Level.
    - **Financial History:** Prior bill amounts, Prior payment history.
- **Class balance (counts or %):** Imbalanced.
    - **Non-defaulters (0):** 23,364.
    - **Defaulters (1):** 6,636 (approx. 22%).

**Preprocessing:**

- **Missing values handling:** Unknown values in 'education' and 'marriage' features were grouped and assigned to an 'others' category.
- **Encoding/scaling:** NR
- **Feature selection (if any):** Correlation matrix used to analyze feature relationships (e.g., positive correlation found between 'payment' and 'bill amount'), but specific removal of features is NR.
- **Imbalance handling (SMOTE/class weights/undersampling/etc.):** NR

**Models compared:**

- Two Class Deep Support Vector Machine (DSVM).
- Two Class Boosted Decision Tree (BDT).
- Two Class Averaged Perceptron (AP).
- Two Class Bayes Point Machine (BPM).

**Validation design:**

- **Train/test split OR k-fold (k=?):** Train/Test split (Split Data module visible in Azure ML pipeline Figure 9, specific ratio NR).
- **Any external validation?:** NR

**Metrics reported:**

- **Accuracy:** Yes (Range: 80.60% – 82.20%).
- **Precision:** Yes (Range: 0.62 – 0.73).
- **Recall:** Yes (Range: 0.20 – 0.45).
- **F1-score:** Yes (Range: 0.31 – 0.52).
- **ROC-AUC:** Yes (Range: 0.73 – 0.77).
- **PR-AUC:** NR
- **Calibration (Brier/calibration curve):** NR
- **Best model + best values:**
    - **Overall Best:** Deep Support Vector Machine (DSVM).
    - **Accuracy:** 82.20%.
    - **AUC:** 0.74.
    - **F1-Score:** 0.47.
    - _Note: Decision Tree achieved a higher AUC (0.77) and F1 (0.52) but lower Accuracy (81.60%) compared to DSVM._

**Statistical test/comparison:** NR

**Explainability:**

- **Feature importance/SHAP/LIME/etc.:** NR
- **Top predictors:** Exploratory analysis suggests "Age" is a predictor (older customers have lower chances of default).

**Key findings (2-4 bullets):**

- **Best Performer:** The Deep Support Vector Machine (DSVM) was identified as the best model for predicting defaulters, achieving an accuracy of 82.20%.
- **Demographic Insights:** The dataset analysis revealed that the bank has more female customers, and the likelihood of defaulting decreases as customer age increases.
- **Model Comparison:** While DSVM had the best accuracy, the Boosted Decision Tree (BDT) achieved the highest ROC-AUC (0.77) and Recall (0.45), suggesting it might be better at identifying actual positive cases despite slightly lower overall accuracy.

**Limitations (from paper):**

- **Memory Intensity:** The authors note that Boosted Decision Trees are memory-intensive learners and their current implementation may not handle very large datasets effectively.
- **Low Sensitivity:** All models exhibited low recall (Sensitivity), ranging from 20% to 45%, indicating a high number of False Negatives (predicting a defaulter as a non-defaulter).

**Deployment/implementation notes (if any):**

- **Platform:** The solution was designed and trained on the **Microsoft Azure Machine Learning** cloud-based platform.
- **Future Work:** Plans to train the system using Multilayer Perceptron.