# CHAPTER II
## REVIEW OF RELATED LITERATURE AND STUDIES

This matrix integrates three sources:
- `Related Paper ML/Exported ItemsML_IEEE.csv`
- `Related Paper ML/Exported Items_ML_scopus.csv`
- `Related Paper ML/Exported Items_Abstract_IncludedPaper.csv`

Evidence grading used in this version: `Full text (PDF available)`, `Abstract-only`, and `Metadata-only`.

---

## A. Search Documentation Log

| Date | Database | Search String ID | Query Used | Filters Applied | Results Returned | Notes |
|---|---|---|---|---|---:|---|
| 2026-02-19 | IEEE Xplore | Q1 | `predictive analytics OR machine learning` with education/compliance/early warning terms | 2019-2026, peer-reviewed sources | 25 | Exported to Zotero CSV and screened. |
| 2026-02-19 | Scopus | Q2 | `predictive analytics OR machine learning` with education/risk/early warning terms | 2019-2026, peer-reviewed sources | 42 | Exported to Zotero CSV and screened. |

---

## B. Inclusion and Exclusion Criteria

### Inclusion Criteria
1. 2019-2026 publication window.
2. Journal article, conference paper, or book section.
3. Predictive analytics or ML-based risk/early warning focus.
4. Transferable to educational compliance/workflow prediction context.
5. Traceable citation metadata (DOI/URL/title/authors).

### Exclusion Criteria
1. Duplicate DOI/title records.
2. Pre-2019 records for this matrix pass.
3. Non-predictive/non-ML papers.
4. Records with unusable metadata.
5. Non-peer-reviewed documents.

---

## C. PRISMA-Style Screening Summary

| Stage | Count |
|---|---:|
| Records identified | 67 |
| Duplicates removed | 1 |
| Records screened (title/abstract metadata) | 56 |
| Studies included in synthesis matrix | 25 |
| Included with full text | 9 |
| Included as abstract-only | 13 |
| Included as metadata-only | 3 |

---

## D. Master Synthesis Matrix (25 Studies)

| # | Authors (Year) | Title | Source | Evidence Level | Domain/Context | Objective/Target Variable | Method/Model(s) | Dataset (size/features/balance) | Validation Strategy | Metrics Reported | Best Result(s) | Key Findings | Limitations Reported | Research Gap Relevant to Your Study |
|---:|---|---|---|---|---|---|---|---|---|---|---|---|---|---|
| 1 | Behl, D. et al. (2026) | Solar optimization via learning-driven visual intelligent analytics | Scopus | Full text (PDF available) | Energy forecasting | - **Objective:** To develop a globally adaptable, end-to-end framework (SOLVIA) for predictive cleaning and intelligent maintenance of photovoltaic (PV) systems to optimize energy yield and minimize maintenance costs. -… | Decision Tree, Random Forest, Linear Regression | - **Source:** Rooftop PV installation (24.12 kW) at Netaji Subhas University of Technology (NSUT), Dwarka, Delhi, India. - **Sample size (n):** Two-year dataset (2021–2023) collected at 15-minute intervals. - **Features… | - **Train/test split OR k-fold (k=?):** - **Split:** 70% Training, 15% Validation, 15% Testing. - **Cross-validation:** Rolling-origin time-series split (5 folds) to pre… | - **Accuracy:** N/A - **Precision:** N/A - **Recall:** N/A - **F1-score:** N/A - **ROC-AUC:** N/A - **PR-AUC:** N/A - **Calibration (Brier/calibration curve):** 95% Pred… | Random Forest Regression. - **RMSE:** 3.8 W. - **MAE:** 2.6 W. - **R²:** 0.95. | - **Predictive Accuracy:** The Random Forest model achieved high accuracy (R² = 0.95) in predicting PV power output, effectively capturing non-linear interactions between dust, weather, and power generation. - **Economi… | - **Sensor Dependence:** The framework relies heavily on the accuracy of environmental and electrical sensor data; sensor failure or calibration drift can impact performance. - **Site-Specific Calibration:** Despite ada… | Domain mismatch; mainly methodological transferability. |
| 2 | S. -S. M. Ajibade et al. (2025) | Machine Learning Techniques for Predictive Analytics of Academic Outcomes and Behavior of Students | IEEE | Full text (PDF available) | Higher education analytics | - **Objective:** To analyze and predict secondary school student performance to aid in early warning systems and personalized interventions. - **Target variable:** Final Grade (G3) converted to Binary Classification. - … | Logistic Regression, Random Forest | - **Source:** Student performance dataset by Paulo Cortez (secondary education students in two Portuguese schools). - **Sample size (n):** Approx. 395 (Inferred from the test set support of 79 representing 20% of the da… | - **Train/test split OR k-fold (k=?):** Train/Test split (80% Training, 20% Testing). - **Any external validation?:** NR | - **Accuracy:** Yes (RF: 92.4%, LR: 89.9%, GB: 86.1%). - **Precision:** Yes (e.g., RF Class 1: 0.98, Class 0: 0.84). - **Recall:** Yes (e.g., RF Class 1: 0.90, Class 0: … | Random Forest achieved the highest accuracy (92.4%) and F1-scores (0.94 for Pass group),. | - **Best Performer:** Random Forest outperformed Logistic Regression and Gradient Boosting, achieving 92.4% accuracy, effectively handling the complex relationships in the data. - **Critical Predictors:** Past academic … | - **Hyperparameter Tuning:** Gradient Boosting's lower performance (86.1%) suggests that the model is sensitive to configuration and requires further tuning of learning rates and estimators to match the other models,. -… | Primarily student-centered; does not directly target faculty portfolio submission compliance. |
| 3 | Murugan, M.S. et al. (2023) | Large-scale data-driven financial risk management & analysis using machine learning strategies | Scopus | Full text (PDF available) | Financial risk and early warning | - **Objective:** To analyze and process large-scale datasets to predict loan defaults and their likelihood using machine learning models integrated with IoT deployment. - **Target variable:** Loan Default / Likelihood o… | Logistic Regression, XGBoost, KNN | - **Source:** Large-scale online datasets gathered from FNCE5313. (Note: The feature names suggest a dataset similar to LendingClub). - **Sample size (n):** "Large-scale" (Specific total $n$ NR, but Table 2 mentions "Hi… | - **Train/test split OR k-fold (k=?):** - **Split:** 30% Training, 70% Testing. - **Cross-validation:** The text mentions testing XG boost using "repeated k-fold cross-v… | - **Accuracy:** Yes (Range: 87%–98%). - **Precision:** Yes (Mentioned as used, values NR in Table 2). - **Recall:** Yes (Mentioned as used, values NR in Table 2). - **F1… | - **KNN:** Achieved the highest accuracy range (97%–98%) and Mean Absolute Error (10%–13%). - **XG Boost:** Accuracy (91%–96%) and Mean Absolute Error (2%–7%). - _Note:_ The autho… | - **Model Performance:** KNN achieved the highest accuracy (97%–98%) compared to XG Boost (91%–96%) and Logistic Regression (87%–95%) in the reported metrics. - **Wealth Management:** The investor’s wealth proportion me… | - **Computational Cost:** KNN can be computationally expensive and time-consuming if the training set is extensive. - **Data Sensitivity:** Large-scale financial data contains sensitive personal information, requiring c… | Transferable risk/compliance logic, but no faculty portfolio workflow integration. |
| 4 | Assous, H.F. (2022) | Prediction of Banks Efficiency Using Feature Selection Method: Comparison between Selected Machine Learning Models | Scopus | Full text (PDF available) | Financial risk and early warning | - **Objective:** To examine the determinants of efficiency for conventional and Islamic Saudi banks and select the best machine learning model to predict this efficiency. - **Target variable:** Cost Efficiency Ratio (Co… | Support Vector Machine, Linear Regression, Feature Selection | - **Source:** Annual financial reports of Saudi banks. - **Sample size (n):** 11 banks (7 conventional, 4 Islamic) observed over 5 years (2014–2018). (Total observations approx. 55). - **Features (count + key features):… | - **Train/test split OR k-fold (k=?):** The data was split into a "training phase" and a "testing phase". (Specific split ratio NR, though Figure 4 suggests a split). - … | - **Accuracy:** NR (Regression task). - **Precision:** NR - **Recall:** NR - **F1-score:** NR - **ROC-AUC:** NR - **PR-AUC:** NR - **Calibration (Brier/calibration curve… | - **Training Phase:** Neural Network (NN) with feature selection (R² = 0.987, RMSE = 1.112). - **Testing Phase:** CHAID with feature selection (R² = 0.985, RMSE = 1.467). The auth… | - **Determinants of Efficiency:** Efficiency in Saudi banks is significantly driven by profitability, liquidity, and managerial practices. Specifically, higher profitability (ROA) improves efficiency (reduces cost ratio… | - The study focused only on cost efficiency, excluding other types like technical or allocative efficiency. - Data was limited to secondary financial reports; qualitative data (interviews) was not considered. - The samp… | Transferable risk/compliance logic, but no faculty portfolio workflow integration. |
| 5 | M. N. Razali et al. (2021) | Performance Evaluation of Masked Face Recognition Using Deep Learning for Covid-19 Standard of Procedure (SOP) Compliance Monitoring | IEEE | Full text (PDF available) | Compliance monitoring | - **Objective:** To evaluate the performance of various Deep Convolutional Neural Network (CNN) models as feature extractors combined with machine learning classifiers to create an effective masked face recognition mode… | Decision Tree, Random Forest, Support Vector Machine, KNN, Deep Learning | - **Source:** "Face Mask Dataset" (reference in paper), a collection comprising the Kaggle Medical Mask dataset and Prajna Bhandary dataset from PyImageSearch. - **Sample size (n):** 11,042 images total. - **Features (c… | - **Train/test split OR k-fold (k=?):** Train/Test split. The images were randomly divided with a **70:30 ratio**. - **Any external validation?:** NR | - **Accuracy:** Yes (Formula: (TP+TN) / (TP+FP+TN+FN)). - **Precision:** NR - **Recall:** NR - **F1-score:** NR - **ROC-AUC:** NR - **PR-AUC:** NR - **Calibration (Brier… | - **Accuracy:** **DENSENET201-SVM** and **EFFNET-LSVM** both achieved the highest accuracy of **0.9972**,. - **Efficiency:** **EFFNET-LSVM** is considered the best overall due to … | - **Top Performance:** Both DENSENET201-SVM and EFFNET-LSVM achieved the highest classification accuracy of 99.72% on the test set,. - **Efficiency Winner:** EFFNET-LSVM is recommended as the superior model for deployme… | - **Dataset Realism:** The paper suggests future work should "acquire the local or real dataset," implying the current collection (though containing real images) might not fully represent the specific target environment… | Transferable risk/compliance logic, but no faculty portfolio workflow integration. |
| 6 | Pradhan, S. et al. (2020) | On the Defect Prediction for Large Scale Software Systems-From Defect Density to Machine Learning | Scopus | Full text (PDF available) | Software engineering risk prediction | - **Objective:** To address "Data Definition" and "SDP Lifecycle" challenges in defect prediction for large-scale software and develop models for continuous quality management throughout the development lifecycle (SDLC)… | Random Forest, XGBoost, Linear Regression | - **Source:** Cisco IOS-XE software (Large-scale commercial software with 200+ million LOC and 2200+ components). - **Sample size (n):** - **Training:** First 6 releases (1,122 observations used in defect density analys… | - **Train/test split OR k-fold (k=?):** Chronological split: Data from the first 6 releases used for training, and data from the last 2 releases used for testing. - **An… | - **Accuracy:** NR - **Precision:** NR - **Recall:** NR - **F1-score:** NR - **ROC-AUC:** NR - **PR-AUC:** NR - **Calibration (Brier/calibration curve):** NR - **Best mo… | - **CC Stage:** XGBoost (Scenario 2) - RMSE: 96, MAE: 42. - **FC Stage:** Linear Regression (VIF ≤ 10) - RMSE: 32, MAE: 12. - **FCA Stage:** Random Forest (VIF ≤ 5) - RMSE: 32, MA… | - **Data Definition Matters:** Component-based models yielded significantly lower prediction errors compared to product-based models (e.g., FCA prediction error dropped from 11.7% to 1.4%). - **Lifecycle Approach:** Usi… | - **Measurement Cost:** Code metrics like cyclomatic complexity and modularity could not be included in the Code Complete (CC) model due to the difficulty and high cost of measurement in such a large system. - **General… | Domain mismatch; mainly methodological transferability. |
| 7 | Shivanna, A. et al. (2020) | Prediction of Defaulters using Machine Learning on Azure ML | Scopus | Full text (PDF available) | Financial risk and early warning | - **Objective:** To build a model based on machine learning techniques that can accurately predict if a credit card customer will be a potential defaulter to aid credit risk management. - **Target variable:** Default pa… | Decision Tree, Support Vector Machine | - **Source:** UCI Machine Learning Repository ("Default of credit card clients" dataset from a Taiwanese bank). - **Sample size (n):** 30,000 observations. - **Features (count + key features):** 25 attributes total (24 … | - **Train/test split OR k-fold (k=?):** Train/Test split (Split Data module visible in Azure ML pipeline Figure 9, specific ratio NR). - **Any external validation?:** NR | - **Accuracy:** Yes (Range: 80.60% – 82.20%). - **Precision:** Yes (Range: 0.62 – 0.73). - **Recall:** Yes (Range: 0.20 – 0.45). - **F1-score:** Yes (Range: 0.31 – 0.52)… | - **Overall Best:** Deep Support Vector Machine (DSVM). - **Accuracy:** 82.20%. - **AUC:** 0.74. - **F1-Score:** 0.47. - _Note: Decision Tree achieved a higher AUC (0.77) and F1 (… | - **Best Performer:** The Deep Support Vector Machine (DSVM) was identified as the best model for predicting defaulters, achieving an accuracy of 82.20%. - **Demographic Insights:** The dataset analysis revealed that th… | - **Memory Intensity:** The authors note that Boosted Decision Trees are memory-intensive learners and their current implementation may not handle very large datasets effectively. - **Low Sensitivity:** All models exhib… | Transferable risk/compliance logic, but no faculty portfolio workflow integration. |
| 8 | A. Kumar Veerasamy et al. (2020) | Using early assessment performance as early warning signs to identify at-risk students in programming courses | IEEE | Full text (PDF available) | Higher education analytics | - To identify at-risk students early in the semester (specifically by Week 3). - **Target variable:** Final Exam Grade (FEG) binary classification: - **At-risk (Class 0):** Failed to sit exam or scored < 60 marks (Grade… | Random Forest, Support Vector Machine | - **Source:** ViLLE Learning Management System (LMS) database from an "Introduction to Programming" course at the University of Turku, Finland. - **Sample size (n):** - **Total:** 217 students across three years used fo… | - **Train/test split OR k-fold (k=?):** - **Training:** 10-fold cross-validation on the 2016 dataset. - **Validation:** 2017 dataset used to verify performance. - **Test… | - **Accuracy:** Overall prediction accuracy reported. - Training (2016): 72.73% - Validation (2017): 52.94% - Testing (2018): 59.64%. - **Precision:** NR - **Recall:** R… | Random Forest on Training set (Accuracy: 72.73%, Recall: 86.84%, AUC: 0.73). | - Students scoring ≤25% in formative assessments during the first two weeks are highly likely (approx. 90%) to fail or not attend the final exam. - Using only the first two weeks of homework and demo exercise scores, th… | - Sample size was not sufficiently large to generalize findings. - The model used only the first two weeks of data; however, student learning is dynamic and performance may change later in the semester. - The validation… | Primarily student-centered; does not directly target faculty portfolio submission compliance. |
| 9 | Liu, H. et al. (2019) | Building engineering safety risk assessment and early warning mechanism construction based on distributed machine learning algorithm | Scopus | Full text (PDF available) | Energy forecasting | - **Objective:** To establish a construction safety evaluation index system and an early warning mechanism that quantifies safety status and identifies potential hazards using distributed computing and extension cloud t… | Not reported | - **Source:** - **Case Study:** Data collected from a specific construction site via safety inspection evaluation forms and expert scoring. - **Performance Testing:** Synthetic or aggregated data ranging from 200 to 800… | - **Train/test split OR k-fold (k=?):** N/A (Not a standard supervised learning setup). The study compares computational time across different data scales and validates … | - **Accuracy:** Reported as a percentage comparison between the distributed node outputs and expert evaluation. (Visualized in Fig 7, generally high/consistent). - **Pre… | - **Speed:** Distributed computing was significantly faster than the conventional method for large datasets (e.g., at 800,000 data points: ~97s vs ~111s, with the gap widening as … | - **Efficiency:** Distributed computing significantly reduces calculation time compared to conventional methods, particularly as data volume exceeds 40,000 entries. - **Handling Uncertainty:** The Extension Cloud Model … | - **Environmental Complexity:** The current model may need improvement to handle complex construction environments with poor equipment conditions. - **Computing Requirements:** Distributed computing can be resource-inte… | Domain mismatch; mainly methodological transferability. |
| 10 | W. Sabbir et al. (2024) | Improving Predictive Analytics for Student Dropout: A Comprehensive Analysis and Model Evaluation | IEEE | Abstract-only | Higher education analytics | Predict student dropout risk for early intervention. | Decision Tree, Random Forest, XGBoost, KNN, Feature Selection | Not reported in abstract/metadata. | ROC curve analysis | ROC-AUC | Not clearly quantified in abstract/metadata. | Predictive modeling applied in stated domain with potentially transferable patterns. | Future work/refinement suggested. | Primarily student-centered; does not directly target faculty portfolio submission compliance. |
| 11 | D. Yang et al. (2024) | Student Learning Behavior Analysis and Early Warning System Based on Machine Learning | IEEE | Abstract-only | Higher education analytics | Predict student engagement/behavior outcomes. | Logistic Regression, Decision Tree, Random Forest, Support Vector Machine | Not reported in abstract/metadata. | confusion matrix, ROC curve analysis | Accuracy, Precision, Recall, F1-score, ROC-AUC | Not clearly quantified in abstract/metadata. | Predictive modeling applied in stated domain with potentially transferable patterns. | Future work/refinement suggested. | Primarily student-centered; does not directly target faculty portfolio submission compliance. |
| 12 | Long, Q. et al. (2023) | Research on Intelligent Early Warning of University Budget Expenditure Based on K-Means Clustering Algorithm | Scopus | Abstract-only | Financial risk and early warning | Generate early warning for risky university budget expenditure. | K-Means | Not reported in abstract/metadata. | Not reported in abstract/metadata. | Not reported in abstract/metadata. | Not clearly quantified in abstract/metadata. | Predictive modeling applied in stated domain with potentially transferable patterns. | Future work/refinement suggested. | Transferable risk/compliance logic, but no faculty portfolio workflow integration. |
| 13 | Wu, X. (2022) | University Financial Early Warning Based on Data Mining Algorithm | Scopus | Abstract-only | Financial risk and early warning | Predict university financial risk states. | Decision Tree | Not reported in abstract/metadata. | Not reported in abstract/metadata. | Not reported in abstract/metadata. | Not clearly quantified in abstract/metadata. | Predictive modeling applied in stated domain with potentially transferable patterns. | Not reported in abstract/metadata. | Transferable risk/compliance logic, but no faculty portfolio workflow integration. |
| 14 | Xia, T. (2025) | Application of decision tree classification algorithm for financial management and risk early warning in universities | Scopus | Abstract-only | Financial risk and early warning | Predict domain-specific risk/outcome variable. | Decision Tree | Not reported in abstract/metadata. | Not reported in abstract/metadata. | Not reported in abstract/metadata. | Not clearly quantified in abstract/metadata. | Predictive modeling applied in stated domain with potentially transferable patterns. | Not reported in abstract/metadata. | Transferable risk/compliance logic, but no faculty portfolio workflow integration. |
| 15 | A. H. A. Aziz et al. (2025) | Predicting Factors of Library Traffic at Public University Using Predictive Analytics and Theory of Reasoned Action (TRA) | IEEE | Abstract-only | Higher education analytics | Predict library visit factors and usage-related outcomes. | Decision Tree, Random Forest, Naive Bayes | Not reported in abstract/metadata. | cross-validation | Accuracy | Not clearly quantified in abstract/metadata. | Predictive modeling applied in stated domain with potentially transferable patterns. | Limitations noted by authors.; Future work/refinement suggested.; Potential bias risk discussed. | Primarily student-centered; does not directly target faculty portfolio submission compliance. |
| 16 | R. Hanapi et al. (2024) | From Clicks to Class Participation: Demystifying Student Engagement Factors with Attribute Ranking and Predictive Analytics | IEEE | Abstract-only | Higher education analytics | Predict student engagement/behavior outcomes. | Logistic Regression | Not reported in abstract/metadata. | Not reported in abstract/metadata. | Accuracy, Precision, Recall, F1-score | Not clearly quantified in abstract/metadata. | Predictive modeling applied in stated domain with potentially transferable patterns. | Not reported in abstract/metadata. | Primarily student-centered; does not directly target faculty portfolio submission compliance. |
| 17 | Kler, R. et al. (2024) | Predicting Career Transitions Through Insights from Academic Background and Workforce Dynamics Using Machine Learning | Scopus | Abstract-only | Higher education analytics | Predict domain-specific risk/outcome variable. | Logistic Regression, Decision Tree, Random Forest | features=22 | Not reported in abstract/metadata. | Accuracy | accuracy of 85% | Predictive modeling applied in stated domain with potentially transferable patterns. | Not reported in abstract/metadata. | Primarily student-centered; does not directly target faculty portfolio submission compliance. |
| 18 | N. Ghemrawi et al. (2023) | Assessment of Health Care Compliance in Managing Pseudomonas Aeruginosa in Urinary Tract Infection Using Machine Learning Techniques | IEEE | Abstract-only | Healthcare prediction/compliance | Predict domain-specific risk/outcome variable. | Random Forest, Support Vector Machine, Linear Regression, Classifier Chain | Not reported in abstract/metadata. | Not reported in abstract/metadata. | Accuracy | Not clearly quantified in abstract/metadata. | Predictive modeling applied in stated domain with potentially transferable patterns. | Future work/refinement suggested. | Domain mismatch; mainly methodological transferability. |
| 19 | G. N. S. Gubbala et al. (2024) | Augmenting Compliance With Motion Generation Through Imitation Learning Using Drop-Stitch Reinforced Inflatable Robot Arm With Rigid Joints | IEEE | Abstract-only | Compliance monitoring | Predict domain-specific risk/outcome variable. | Machine learning models (unspecified) | Not reported in abstract/metadata. | Not reported in abstract/metadata. | Not reported in abstract/metadata. | Not clearly quantified in abstract/metadata. | Predictive modeling applied in stated domain with potentially transferable patterns. | Limitations noted by authors. | Transferable risk/compliance logic, but no faculty portfolio workflow integration. |
| 20 | N. Anute et al. (2025) | AI-Powered Predictive Analytics in Consumer Behavior: A Machine Learning Approach for Marketing Strategy Optimization | IEEE | Metadata-only | Consumer behavior analytics | Predict student engagement/behavior outcomes. | Machine learning models (unspecified) | Not reported in abstract/metadata. | Not reported in abstract/metadata. | Not reported in abstract/metadata. | Not reported in abstract/metadata. | Only bibliographic metadata available. | Not reported in abstract/metadata. | Domain mismatch; mainly methodological transferability. |
| 21 | Vonitsanos, G. et al. (2024) | Evaluating Machine Learning Techniques for Enhanced Prediction of Building Energy Consumption | Scopus | Abstract-only | Energy forecasting | Predict energy-related consumption/output patterns. | Decision Tree, Random Forest, Support Vector Machine, KNN | 3 Cornell University buildings | Not reported in abstract/metadata. | Accuracy | Not clearly quantified in abstract/metadata. | Predictive modeling applied in stated domain with potentially transferable patterns. | Not reported in abstract/metadata. | Domain mismatch; mainly methodological transferability. |
| 22 | P. Daothong et al. (2024) | Utilizing Machine Learning Predictive Analytics to Enhance Early Sepsis Diagnosis in Critical Care Setting | IEEE | Abstract-only | Healthcare prediction/compliance | Predict early sepsis diagnosis in critical care. | XGBoost, Deep Learning | eICU database; class balancing applied | 10-fold cross-validation | Accuracy, F1-score, ROC-AUC, Brier score | AUROC = 0.78; Accuracy = 80; F1-Score = 72 | Predictive modeling applied in stated domain with potentially transferable patterns. | Future work/refinement suggested.; False-positive rate concern reported. | Domain mismatch; mainly methodological transferability. |
| 23 | Chouhan, R.L. et al. (2026) | Decoding Urban Growth: Systematic Review Where Machine Learning Meets Geographic Information Systems for Spatial Predictions | Scopus | Abstract-only | Urban analytics and forecasting | Predict domain-specific risk/outcome variable. | Deep Learning | Not reported in abstract/metadata. | Not reported in abstract/metadata. | Not reported in abstract/metadata. | Not clearly quantified in abstract/metadata. | Predictive modeling applied in stated domain with potentially transferable patterns. | Not reported in abstract/metadata. | Domain mismatch; mainly methodological transferability. |
| 24 | M. Kartiwi et al. (2024) | Predictive Analytics for Learning Performance in First-Year University Programming Course | IEEE | Metadata-only | Higher education analytics | Predict domain-specific risk/outcome variable. | Not reported | Not reported in abstract/metadata. | Not reported in abstract/metadata. | Not reported in abstract/metadata. | Not reported in abstract/metadata. | Only bibliographic metadata available. | Not reported in abstract/metadata. | Primarily student-centered; does not directly target faculty portfolio submission compliance. |
| 25 | Uma Maheswari Kalia Moorthy et al. (2025) | Explainability and Regulatory Compliance in Healthcare | IEEE | Metadata-only | Healthcare prediction/compliance | Predict domain-specific risk/outcome variable. | Not reported | Not reported in abstract/metadata. | Not reported in abstract/metadata. | Not reported in abstract/metadata. | Not reported in abstract/metadata. | Only bibliographic metadata available. | Not reported in abstract/metadata. | Domain mismatch; mainly methodological transferability. |

---

## E. Thematic Clustering Table

| Theme | Description | Related Study Numbers (#) | Emerging Insight | Gap for Present Study |
|---|---|---|---|---|
| T1: Early Warning in Education | Student/university prediction and warning studies. | 2, 8, 10, 11, 15, 16, 17, 24 | Strong student-focused evidence base exists. | Limited direct focus on faculty portfolio submission compliance. |
| T2: ML Algorithms for Risk Classification | Use of tree-based, linear, kernel, and ensemble methods. | 1, 2, 3, 4, 6, 7, 8, 10, 11, 13, 14, 16, 19, 21, 22, 24, 25 | Model comparison is common, especially RF/SVM/XGBoost in full-text and abstract evidence. | Need one standardized model comparison on faculty-portfolio data. |
| T3: Imbalanced Data and Evaluation Metrics | Evaluation of rare-risk events and threshold trade-offs. | 3, 5, 25 | Some studies report ROC-AUC and class-balance handling. | Consistent PR-AUC and calibration reporting remains limited. |
| T4: Explainability and Feature Importance | Feature ranking/selection and interpretable factors. | 4, 10 | Explainability appears in selected studies via feature importance/selection. | Faculty compliance models should include interpretable risk factors for administrators. |
| T5: Deployment in Academic Workflows | Practical integration into institutional processes and dashboards. | 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 19, 24 | Operational use is discussed but integration depth varies. | Present study should deliver deployment-ready integration in the web portfolio system. |

---

## F. Methodological Comparison Table

| Study # | Algorithm Family | Validation Design | Primary Metric | Handles Imbalance? | Calibration Reported? | Explainability Used? | Transferable to Faculty Portfolio Context? |
|---:|---|---|---|---|---|---|---|
| 1 | Tree-based / Ensemble | - **Train/test split OR k-fold (k=?):** - **Split:** 70% Training, 15% Validation, 15% Testing. - **Cross-validation:** Rolling-origin time-series split (5 folds) to pre… | - **Accuracy:** N/A - **Precision:** N/A - **Recall:** N/A - **F1-score:** N/A - **ROC-AUC:** N/A - **PR-AUC:** N/A - **Calibration (Brier/calibration curve):** 95% Pred… | Not reported | Yes | No | Low |
| 2 | Tree-based / Ensemble | - **Train/test split OR k-fold (k=?):** Train/Test split (80% Training, 20% Testing). - **Any external validation?:** NR | - **Accuracy:** Yes (RF: 92.4% | Not reported | Not reported | No | High |
| 3 | Linear models | - **Train/test split OR k-fold (k=?):** - **Split:** 30% Training, 70% Testing. - **Cross-validation:** The text mentions testing XG boost using "repeated k-fold cross-v… | - **Accuracy:** Yes (Range: 87%–98%). - **Precision:** Yes (Mentioned as used | Not reported | Not reported | No | Medium |
| 4 | Linear models | - **Train/test split OR k-fold (k=?):** The data was split into a "training phase" and a "testing phase". (Specific split ratio NR, though Figure 4 suggests a split). - … | - **Accuracy:** NR (Regression task). - **Precision:** NR - **Recall:** NR - **F1-score:** NR - **ROC-AUC:** NR - **PR-AUC:** NR - **Calibration (Brier/calibration curve… | Not reported | Yes | Yes | Medium |
| 5 | Tree-based / Ensemble | - **Train/test split OR k-fold (k=?):** Train/Test split. The images were randomly divided with a **70:30 ratio**. - **Any external validation?:** NR | - **Accuracy:** Yes (Formula: (TP+TN) / (TP+FP+TN+FN)). - **Precision:** NR - **Recall:** NR - **F1-score:** NR - **ROC-AUC:** NR - **PR-AUC:** NR - **Calibration (Brier… | Not reported | Yes | No | Medium |
| 6 | Tree-based / Ensemble | - **Train/test split OR k-fold (k=?):** Chronological split: Data from the first 6 releases used for training, and data from the last 2 releases used for testing. - **An… | - **Accuracy:** NR - **Precision:** NR - **Recall:** NR - **F1-score:** NR - **ROC-AUC:** NR - **PR-AUC:** NR - **Calibration (Brier/calibration curve):** NR - **Best mo… | Not reported | Yes | No | Low |
| 7 | Tree-based / Ensemble | - **Train/test split OR k-fold (k=?):** Train/Test split (Split Data module visible in Azure ML pipeline Figure 9, specific ratio NR). - **Any external validation?:** NR | - **Accuracy:** Yes (Range: 80.60% – 82.20%). - **Precision:** Yes (Range: 0.62 – 0.73). - **Recall:** Yes (Range: 0.20 – 0.45). - **F1-score:** Yes (Range: 0.31 – 0.52)… | Not reported | Not reported | No | Medium |
| 8 | Tree-based / Ensemble | - **Train/test split OR k-fold (k=?):** - **Training:** 10-fold cross-validation on the 2016 dataset. - **Validation:** 2017 dataset used to verify performance. - **Test… | - **Accuracy:** Overall prediction accuracy reported. - Training (2016): 72.73% - Validation (2017): 52.94% - Testing (2018): 59.64%. - **Precision:** NR - **Recall:** R… | Not reported | Not reported | No | High |
| 9 | Classical ML (unspecified) | - **Train/test split OR k-fold (k=?):** N/A (Not a standard supervised learning setup). The study compares computational time across different data scales and validates … | - **Accuracy:** Reported as a percentage comparison between the distributed node outputs and expert evaluation. (Visualized in Fig 7 | Not reported | Not reported | No | Low |
| 10 | Tree-based / Ensemble | ROC curve analysis | ROC-AUC | Not reported | Not reported | Yes | High |
| 11 | Tree-based / Ensemble | confusion matrix, ROC curve analysis | Accuracy | Not reported | Not reported | No | High |
| 12 | Distance/Clustering | Not reported in abstract/metadata. | Not reported in abstract/metadata. | Not reported | Not reported | No | Medium |
| 13 | Tree-based / Ensemble | Not reported in abstract/metadata. | Not reported in abstract/metadata. | Not reported | Not reported | No | Medium |
| 14 | Tree-based / Ensemble | Not reported in abstract/metadata. | Not reported in abstract/metadata. | Not reported | Not reported | No | Medium |
| 15 | Tree-based / Ensemble | cross-validation | Accuracy | Not reported | Not reported | No | High |
| 16 | Linear models | Not reported in abstract/metadata. | Accuracy | Not reported | Not reported | No | High |
| 17 | Tree-based / Ensemble | Not reported in abstract/metadata. | Accuracy | Not reported | Not reported | No | High |
| 18 | Tree-based / Ensemble | Not reported in abstract/metadata. | Accuracy | Not reported | Not reported | No | Low |
| 19 | Classical ML (unspecified) | Not reported in abstract/metadata. | Not reported in abstract/metadata. | Not reported | Not reported | No | Medium |
| 20 | Classical ML (unspecified) | Not reported in abstract/metadata. | Not reported in abstract/metadata. | Not reported | Not reported | No | Low |
| 21 | Tree-based / Ensemble | Not reported in abstract/metadata. | Accuracy | Not reported | Not reported | No | Low |
| 22 | Deep learning | 10-fold cross-validation | Accuracy | Not reported | Yes | No | Low |
| 23 | Deep learning | Not reported in abstract/metadata. | Not reported in abstract/metadata. | Not reported | Not reported | No | Low |
| 24 | Classical ML (unspecified) | Not reported in abstract/metadata. | Not reported in abstract/metadata. | Not reported | Not reported | No | High |
| 25 | Classical ML (unspecified) | Not reported in abstract/metadata. | Not reported in abstract/metadata. | Not reported | Not reported | No | Low |

---

## G. Metrics Benchmark Summary

| Metric | Lowest Reported | Median Reported | Highest Reported | Notes |
|---|---:|---:|---:|---|
| Accuracy | 80.00% | 82.50% | 85.00% | Derived from available full-text and abstract-reported values; verify values against final manuscript tables before Chapter IV benchmarking. |
| Precision | N/A | N/A | N/A | Derived from available full-text and abstract-reported values; verify values against final manuscript tables before Chapter IV benchmarking. |
| Recall | N/A | N/A | N/A | Derived from available full-text and abstract-reported values; verify values against final manuscript tables before Chapter IV benchmarking. |
| F1-score | 72.00% | 72.00% | 72.00% | Derived from available full-text and abstract-reported values; verify values against final manuscript tables before Chapter IV benchmarking. |
| ROC-AUC | 78.00% | 78.00% | 78.00% | Derived from available full-text and abstract-reported values; verify values against final manuscript tables before Chapter IV benchmarking. |
| PR-AUC | N/A | N/A | N/A | Derived from available full-text and abstract-reported values; verify values against final manuscript tables before Chapter IV benchmarking. |

---

## H. Research Gap Synthesis (Drafting Block)

### H.1 Empirical Gaps
1. Most evidence centers on student outcomes, financial risk, or non-education domains rather than faculty portfolio submission compliance.
2. Cross-study operational evidence for faculty-focused submission workflows is still sparse.
3. Multi-institution and faculty-specific compliance datasets are rarely reported.

### H.2 Methodological Gaps
1. Not all studies report class imbalance handling and threshold policy in enough detail.
2. Calibration reporting is limited compared to discrimination metrics.
3. PR-AUC reporting is inconsistent, even when problems are likely imbalanced.

### H.3 Contextual Gaps
1. Few studies integrate predictive models directly into a web-based faculty portfolio management workflow.
2. Administrative explainability requirements are not consistently addressed.
3. Institution-specific policy and process constraints are underrepresented in current models.

### H.4 Final Gap Statement for Present Study

> Current literature supports machine learning-based early warning across several domains, yet direct, deployment-oriented prediction of late or incomplete faculty portfolio submissions remains limited. This study addresses that gap through a quantitative predictive model integrated into a web-based Faculty Portfolio Management System, with emphasis on comparable metrics including ROC-AUC and PR-AUC.

---

## I. Citation Tracking Sheet

| # | Full APA/IEEE Citation | DOI/URL | Database | Evidence Level | Included (Y/N) | Reason for Exclusion (if N) |
|---:|---|---|---|---|---|---|
| 1 | Behl, D.; Tomar, A.; Kumar, H.; Sharma, S. (2026). Solar optimization via learning-driven visual intelligent analytics. Renewable Energy. | 10.1016/j.renene.2025.125171 | Scopus | Full text (PDF available) | Y |  |
| 2 | S. -S. M. Ajibade; N. A. Goles; M. C. Villagonzalo; R. F. B. Legaspino; C. P. Antecristo; J. P. Dayupay; C. P. Tapales; F. G. Cababat; A. O. Adediran; K. A. Akintoye; O. E. Ayodele (2025). Machine Learning Techniques for Predictive Analytics of Academic Outcomes and Behavior of Students. 2025 IEEE International Conference on Artificial Intelligence in Engineering and Technology (IICAIET). | 10.1109/IICAIET67254.2025.11265617 | IEEE | Full text (PDF available) | Y |  |
| 3 | Murugan, M.S.; T, S.K. (2023). Large-scale data-driven financial risk management & analysis using machine learning strategies. Measurement: Sensors. | 10.1016/j.measen.2023.100756 | Scopus | Full text (PDF available) | Y |  |
| 4 | Assous, H.F. (2022). Prediction of Banks Efficiency Using Feature Selection Method: Comparison between Selected Machine Learning Models. Complexity. | 10.1155/2022/3374489 | Scopus | Full text (PDF available) | Y |  |
| 5 | M. N. Razali; A. S. Shafie; R. Hanapi (2021). Performance Evaluation of Masked Face Recognition Using Deep Learning for Covid-19 Standard of Procedure (SOP) Compliance Monitoring. 2021 6th IEEE International Conference on Recent Advances and Innovations in Engineering (ICRAIE). | 10.1109/ICRAIE52900.2021.9703986 | IEEE | Full text (PDF available) | Y |  |
| 6 | Pradhan, S.; Nanniyur, V.; Vissapragada, P.K. (2020). On the Defect Prediction for Large Scale Software Systems-From Defect Density to Machine Learning. Source title not captured. | 10.1109/QRS51102.2020.00056 | Scopus | Full text (PDF available) | Y |  |
| 7 | Shivanna, A.; Agrawal, D.P. (2020). Prediction of Defaulters using Machine Learning on Azure ML. Source title not captured. | 10.1109/IEMCON51383.2020.9284884 | Scopus | Full text (PDF available) | Y |  |
| 8 | A. Kumar Veerasamy; D. D’Souza; M. -V. Apiola; M. -J. Laakso; T. Salakoski (2020). Using early assessment performance as early warning signs to identify at-risk students in programming courses. 2020 IEEE Frontiers in Education Conference (FIE). | 10.1109/FIE44824.2020.9274277 | IEEE | Full text (PDF available) | Y |  |
| 9 | Liu, H.; Tian, G. (2019). Building engineering safety risk assessment and early warning mechanism construction based on distributed machine learning algorithm. Safety Science. | 10.1016/j.ssci.2019.08.022 | Scopus | Full text (PDF available) | Y |  |
| 10 | W. Sabbir; M. Abdullah-Al-Kafi; A. S. Afridi; M. S. Rahman; M. Karmakar (2024). Improving Predictive Analytics for Student Dropout: A Comprehensive Analysis and Model Evaluation. 2024 11th International Conference on Computing for Sustainable Global Development (INDIACom). | 10.23919/INDIACom61295.2024.10498520 | IEEE | Abstract-only | Y |  |
| 11 | D. Yang; Y. Feng; J. Jiang (2024). Student Learning Behavior Analysis and Early Warning System Based on Machine Learning. 2024 International Conference on Language Technology and Digital Humanities (LTDH). | 10.1109/LTDH64262.2024.00042 | IEEE | Abstract-only | Y |  |
| 12 | Long, Q.; Zhu, W. (2023). Research on Intelligent Early Warning of University Budget Expenditure Based on K-Means Clustering Algorithm. Source title not captured. | 10.1109/ITME60234.2023.00126 | Scopus | Abstract-only | Y |  |
| 13 | Wu, X. (2022). University Financial Early Warning Based on Data Mining Algorithm. Source title not captured. | 10.1007/978-3-031-05484-6_143 | Scopus | Abstract-only | Y |  |
| 14 | Xia, T. (2025). Application of decision tree classification algorithm for financial management and risk early warning in universities. Journal of Computational Methods in Sciences and Engineering. | 10.1177/14727978251319399 | Scopus | Abstract-only | Y |  |
| 15 | A. H. A. Aziz; S. N. H. Ishak; W. S. D. W. A. Ghani (2025). Predicting Factors of Library Traffic at Public University Using Predictive Analytics and Theory of Reasoned Action (TRA). 2025 6th International Conference on Artificial Intelligence and Data Sciences (AiDAS). | 10.1109/AiDAS67696.2025.11213939 | IEEE | Abstract-only | Y |  |
| 16 | R. Hanapi; M. N. Razali; S. Yahya; S. A. A. Seman; S. Halamy; E. A. Rahim (2024). From Clicks to Class Participation: Demystifying Student Engagement Factors with Attribute Ranking and Predictive Analytics. 2024 5th International Conference on Artificial Intelligence and Data Sciences (AiDAS). | 10.1109/AiDAS63860.2024.10730411 | IEEE | Abstract-only | Y |  |
| 17 | Kler, R.; Singh, G.; Chaudhary, N.; Abdullaev, B.; Bhandwal, M.; Ather, D. (2024). Predicting Career Transitions Through Insights from Academic Background and Workforce Dynamics Using Machine Learning. Source title not captured. | 10.1109/ICTACS62700.2024.10840625 | Scopus | Abstract-only | Y |  |
| 18 | N. Ghemrawi; K. Safi; J. El Falou (2023). Assessment of Health Care Compliance in Managing Pseudomonas Aeruginosa in Urinary Tract Infection Using Machine Learning Techniques. 2023 Seventh International Conference on Advances in Biomedical Engineering (ICABME). | 10.1109/ICABME59496.2023.10293106 | IEEE | Abstract-only | Y |  |
| 19 | G. N. S. Gubbala; M. Nagashima; H. Mori; Y. A. Seong; H. Sato; R. Niiyama; Y. Suga; T. Ogata (2024). Augmenting Compliance With Motion Generation Through Imitation Learning Using Drop-Stitch Reinforced Inflatable Robot Arm With Rigid Joints. IEEE Robotics and Automation Letters. | 10.1109/LRA.2024.3446270 | IEEE | Abstract-only | Y |  |
| 20 | N. Anute; N. V. Limbore; Y. Lahoti; P. Kalshetti (2025). AI-Powered Predictive Analytics in Consumer Behavior: A Machine Learning Approach for Marketing Strategy Optimization. 2025 International Conference on Innovations in Intelligent Systems: Advancements in Computing, Communication, and Cybersecurity (ISAC3). | 10.1109/ISAC364032.2025.11156432 | IEEE | Metadata-only | Y |  |
| 21 | Vonitsanos, G.; Kanavos, A.; Mylonas, P. (2024). Evaluating Machine Learning Techniques for Enhanced Prediction of Building Energy Consumption. Source title not captured. | 10.1109/SEEDA-CECNSM63478.2024.00018 | Scopus | Abstract-only | Y |  |
| 22 | P. Daothong; S. Jampa-ngern; W. Senavongse (2024). Utilizing Machine Learning Predictive Analytics to Enhance Early Sepsis Diagnosis in Critical Care Setting. 2024 IEEE/ACIS 9th International Conference on Big Data, Cloud Computing, and Data Science (BCD). | 10.1109/BCD61269.2024.10743073 | IEEE | Abstract-only | Y |  |
| 23 | Chouhan, R.L.; Shekhawat, H.S. (2026). Decoding Urban Growth: Systematic Review Where Machine Learning Meets Geographic Information Systems for Spatial Predictions. Source title not captured. | 10.1007/978-981-96-7760-3_13 | Scopus | Abstract-only | Y |  |
| 24 | M. Kartiwi; T. S. Gunawan; N. M. Yusoff (2024). Predictive Analytics for Learning Performance in First-Year University Programming Course. 2024 IEEE 10th International Conference on Smart Instrumentation, Measurement and Applications (ICSIMA). | 10.1109/ICSIMA62563.2024.10675540 | IEEE | Metadata-only | Y |  |
| 25 | Uma Maheswari Kalia Moorthy; Asthampatti Marimuthu Jayapalan Muthukumaran; Vijayalakshmi Kaliyaperumal; Shobana Jayakumar; Kalpana Ayanellore Vijayaraghavan (2025). Explainability and Regulatory Compliance in Healthcare. Explainable Artificial Intelligence in the Healthcare Industry. | http://ieeexplore.ieee.org/document/11236010 | IEEE | Metadata-only | Y |  |

---

## J. Writing Map for Chapter II

1. Global-to-local evolution of predictive early warning in higher education and compliance-related settings
2. Algorithmic patterns in prior studies (tree-based, kernel-based, linear, and ensemble approaches)
3. Metric standards and reporting quality (Accuracy, Precision, Recall, F1-score, ROC-AUC, PR-AUC, calibration)
4. Model comparison and validation designs in prior research
5. Explainability and deployment implications for academic administrators
6. Final synthesis of gaps leading to this faculty portfolio early warning study

### Next Data-Completion Step
- For `Abstract-only` and `Metadata-only` studies, continue filling missing dataset, validation, calibration, and limitation details when additional full text becomes available.