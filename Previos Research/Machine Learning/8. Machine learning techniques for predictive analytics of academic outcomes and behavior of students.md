**Study ID/Title:** S.-S. M. Ajibade et al. (2025) - "Machine Learning Techniques for Predictive Analytics of Academic Outcomes and Behavior of Students"

**Objective/Target variable:**

- **Objective:** To analyze and predict secondary school student performance to aid in early warning systems and personalized interventions.
- **Target variable:** Final Grade (G3) converted to Binary Classification.
    - **Pass (1):** Grade â‰¥ 10.
    - **Fail (0):** Grade < 10.

**Dataset:**

- **Source:** Student performance dataset by Paulo Cortez (secondary education students in two Portuguese schools).
- **Sample size (n):** Approx. 395 (Inferred from the test set support of 79 representing 20% of the data),.
- **Features (count + key features):** 33 attributes. Key features include:
    - **Academic:** G1 and G2 (previous grades), study time, absences.
    - **Demographic/Social:** Age, gender, family history, parental education level,.
- **Class balance (counts or %):** Imbalanced (based on Test Set):
    - **Fail (0):** 27 (34%).
    - **Pass (1):** 52 (66%).

**Preprocessing:**

- **Missing values handling:** Data was reviewed; no missing values were found, so no imputation was needed.
- **Encoding/scaling:**
    - **One-hot encoding:** Used for categorical features like "gender" and "school".
    - **Ordinal encoding:** Used for ordinal features like "parental education level".
    - **StandardScaler:** Used to standardize numerical features like "study time" and "absences".
- **Feature selection (if any):** NR
- **Imbalance handling (SMOTE/class weights/undersampling/etc.):** NR

**Models compared:**

- Random Forest (RF)
- Logistic Regression (LR)
- Gradient Boosting (GB)

**Validation design:**

- **Train/test split OR k-fold (k=?):** Train/Test split (80% Training, 20% Testing).
- **Any external validation?:** NR

**Metrics reported:**

- **Accuracy:** Yes (RF: 92.4%, LR: 89.9%, GB: 86.1%).
- **Precision:** Yes (e.g., RF Class 1: 0.98, Class 0: 0.84).
- **Recall:** Yes (e.g., RF Class 1: 0.90, Class 0: 0.96).
- **F1-score:** Yes (e.g., RF Class 1: 0.94, Class 0: 0.90).
- **ROC-AUC:** NR
- **PR-AUC:** NR
- **Calibration (Brier/calibration curve):** NR
- **Best model + best values:** Random Forest achieved the highest accuracy (92.4%) and F1-scores (0.94 for Pass group),.

**Statistical test/comparison:** NR

**Explainability:**

- **Feature importance/SHAP/LIME/etc.:** Feature importance analysis performed for Random Forest.
- **Top predictors:** Previous academic performance (G1 and G2) were identified as the most critical predictors. Study habits and parental education were also noted as relevant,.

**Key findings (2-4 bullets):**

- **Best Performer:** Random Forest outperformed Logistic Regression and Gradient Boosting, achieving 92.4% accuracy, effectively handling the complex relationships in the data.
- **Critical Predictors:** Past academic grades (G1, G2) are the strongest indicators of final success, confirming that early academic performance is highly predictive of future results.
- **Model Viability:** Logistic Regression provided robust results (89.9% accuracy) and high interpretability, making it a viable alternative for understanding specific factor influences, whereas Gradient Boosting (86.1%) underperformed, likely requiring more hyperparameter tuning.

**Limitations (from paper):**

- **Hyperparameter Tuning:** Gradient Boosting's lower performance (86.1%) suggests that the model is sensitive to configuration and requires further tuning of learning rates and estimators to match the other models,.
- **Linear Boundaries:** Logistic Regression's slightly lower accuracy compared to Random Forest is attributed to its linear decision boundary, which may fail to capture complex feature relationships.

**Deployment/implementation notes (if any):**

- **Educational Intervention:** The models are proposed for use in "early warning systems" to help educators and policymakers identify at-risk students early and create personalized learning plans.