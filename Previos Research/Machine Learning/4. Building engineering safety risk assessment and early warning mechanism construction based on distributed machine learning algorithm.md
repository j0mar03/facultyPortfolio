**Study ID/Title:** Hongmei Liu and Guiliang Tian (2019) - "Building engineering safety risk assessment and early warning mechanism construction based on distributed machine learning algorithm"

**Objective/Target variable:**

- **Objective:** To establish a construction safety evaluation index system and an early warning mechanism that quantifies safety status and identifies potential hazards using distributed computing and extension cloud theory.
- **Target variable:** Safety Warning Level (Categorical/Ordinal).
    - **Classes:** No warning (Level I), Minor warning (Level II), Intermediate warning (Level III), Severe warning (Level IV).

**Dataset:**

- **Source:**
    - **Case Study:** Data collected from a specific construction site via safety inspection evaluation forms and expert scoring.
    - **Performance Testing:** Synthetic or aggregated data ranging from 200 to 800,000 data points used to test computational speed.
- **Sample size (n):**
    - **Case Study:** 1 construction site evaluated by 10 experts.
    - **Performance Test:** Simulated data loads of 200, 2,000, 20,000, 200,000, and 800,000.
- **Features (count + key features):** 3 primary indicators broken down into secondary and tertiary indicators (Total count approx. 15-20 based on Table 1).
    - **Human factors:** Worker safety ideological quality, rule obedience, participation rate, etc..
    - **Factor of substance:** Safety culture quality, machinery condition, material qualification rate, safety signs, etc..
    - **Environmental factors:** Technical environment (geology/weather), operation environment (ventilation/lighting), surrounding environment (pipelines).
    - **Management factors:** Safety fund investment, training rate, inspection ratio, etc..
- **Class balance (counts or %):** NR (Case study result was "Minor warning").

**Preprocessing:**

- **Missing values handling:** NR
- **Encoding/scaling:**
    - **Extension Cloud Theory:** Used to transform qualitative concepts and expert scores into quantitative "Cloud" values (Expectation $Ex$, Entropy $En$, Hyper Entropy $He$) to handle fuzziness and randomness.
    - **Normalization:** Index scores are ratios/percentages relative to national standards.
- **Feature selection (if any):**
    - **Analytic Hierarchy Process (AHP):** Used to determine the weight of each index.
    - **Entropy Weight Method:** Used to modify the AHP weights to ensure objectivity.
- **Imbalance handling (SMOTE/class weights/undersampling/etc.):** NR

**Models compared:**

- **Proposed Model:** Extension Cloud Model implemented via Distributed Computing (3-tier architecture).
- **Baseline/Comparison:**
    - "Conventional method" (Traditional serial computing) used to compare processing speed.
    - Manual Expert Judgment (Average of 10 experts) used to validate accuracy.

**Validation design:**

- **Train/test split OR k-fold (k=?):** N/A (Not a standard supervised learning setup). The study compares computational time across different data scales and validates accuracy against a "Real Value" (expert consensus) in a case study.
- **Any external validation?:** Verified via a specific engineering example (case study).

**Metrics reported:**

- **Accuracy:** Reported as a percentage comparison between the distributed node outputs and expert evaluation. (Visualized in Fig 7, generally high/consistent).
- **Precision:** NR
- **Recall:** NR
- **F1-score:** NR
- **ROC-AUC:** NR
- **PR-AUC:** NR
- **Calibration (Brier/calibration curve):** NR
- **Best model + best values:**
    - **Speed:** Distributed computing was significantly faster than the conventional method for large datasets (e.g., at 800,000 data points: ~97s vs ~111s, with the gap widening as data increases).
    - **Accuracy:** The proposed algorithm's results were "basically consistent with the real value" (expert assessment).

**Statistical test/comparison:**

- **Speed Analysis:** Comparison of processing time (seconds) between conventional and distributed methods across increasing data volumes.
- **Accuracy Analysis:** Comparison of distributed node accuracy against the average value of 10 experts.

**Explainability:**

- **Feature importance:** AHP and Entropy methods assigned weights to features. For the warning model case study, the weights ($U_1$) for key elements were:
    - **Scaffold ($e_3$) & Equipment ($e_5$):** 0.16 (Highest).
    - **Template engineering ($e_4$):** 0.14.
    - **Employee safety education ($e_1$):** 0.1.
- **Top predictors:** In the specific case study, the site was rated "Minor warning" generally, but specific weaknesses were identified in "Personnel" and "Technology" based on the correlation scores.

**Key findings (2-4 bullets):**

- **Efficiency:** Distributed computing significantly reduces calculation time compared to conventional methods, particularly as data volume exceeds 40,000 entries.
- **Handling Uncertainty:** The Extension Cloud Model effectively addresses the fuzziness and randomness inherent in construction safety evaluation, transforming qualitative expert scores into quantitative risk levels.
- **Case Study Utility:** The model successfully diagnosed a construction site with a "Light" (Minor) warning level, correctly identifying that while material/equipment controls were good, management and technical operations required improvement.

**Limitations (from paper):**

- **Environmental Complexity:** The current model may need improvement to handle complex construction environments with poor equipment conditions.
- **Computing Requirements:** Distributed computing can be resource-intensive; the authors note a need to develop methods with "low computing performance requirements" for sites with poor infrastructure.
- **Reliance on Expert Input:** The inputs (Cloud drops) rely on scores from construction personnel and experts, retaining some subjectivity.

**Deployment/implementation notes (if any):**

- **Architecture:** Uses a three-tier distributed computing architecture (Client/Server/Database or Master/Worker nodes) to enable collaborative work (CSCW) and resource sharing.
- **Feedback Loop:** The system is designed not just to judge the state but to identify potential problems based on information feedback for guiding the construction process.