# FPMS Survey Questionnaire and Research Instrument

## Title
Faculty Portfolio Management System (FPMS): Usability, Acceptance, Workflow, and Governance Evaluation Questionnaire

## Purpose
This instrument is designed to gather quantitative data for the evaluation variables defined in Chapter III:

1. Workflow efficiency profile (organization, tracking, and turnaround support perceptions)
2. Compliance and governance support (required-document completeness, role governance, and traceability/report readiness)
3. Usability and user acceptance

## Basis from Related Studies
This questionnaire is grounded on established and related literature:

1. **System Usability Scale (SUS)** by Brooke (1996) for usability assessment.
2. **Technology Acceptance Model (TAM)** by Davis (1989) for perceived usefulness, perceived ease of use, and behavioral intention.
3. Related HEI workflow/evaluation system studies from your Chapter II synthesis (e.g., FEDesk, faculty appraisal/ranking systems, e-portfolio workflow studies).

## Respondent Eligibility
Respondents must be active FPMS users who have performed at least one actual task in the system during the evaluation period.

Eligible roles:
- Faculty
- Chair/Reviewer
- Administrator/Auditor

## Response Scale
Use a 5-point Likert scale for all closed-ended items:

- 5 = Strongly Agree
- 4 = Agree
- 3 = Neutral
- 2 = Disagree
- 1 = Strongly Disagree

## Alignment to Chapter I Priority Problems

1. **Problem 1: Post-implementation workflow profile**
   - Sections used: `WI` and `RT`
2. **Problem 2: Post-implementation compliance and governance profile**
   - Sections used: `CS` and `GT`
3. **Problem 3: Usability and user acceptance**
   - Sections used: `SUS` and `TAM (PU, PEOU, BI)`

---

## Section A. Respondent Profile

A1. Role in FPMS:
- Faculty
- Chair/Reviewer
- Administrator
- Auditor

A2. Department/Program:

A3. Years of service in the institution:
- Less than 1 year
- 1-3 years
- 4-7 years
- 8-12 years
- More than 12 years

A4. FPMS usage frequency:
- Daily
- Weekly
- Twice a month
- Monthly
- As needed only

A5. Main device used to access FPMS:
- Desktop/Laptop
- Mobile phone
- Tablet

---

## Section B. Workflow Improvement (WI)

Please rate each statement.

- WI1. The FPMS made the portfolio submission process more organized.
- WI2. The FPMS reduced manual follow-ups between faculty and reviewers.
- WI3. The FPMS made it easier to track the current status of each portfolio.
- WI4. The FPMS reduced duplicated or misplaced submission files.
- WI5. The FPMS improved coordination among faculty, chairs, and administrators.
- WI6. Overall, FPMS improved the efficiency of the portfolio workflow.

---

## Section C. Completeness Support (CS)

- CS1. The system clearly shows the required portfolio documents.
- CS2. The system helps me identify which documents are still missing.
- CS3. The completeness checking feature prevents incomplete submissions.
- CS4. The completeness rules in the system are easy to understand.
- CS5. The system helped improve the quality/completeness of submitted portfolios.

---

## Section D. Review Turnaround Support (RT)

- RT1. The system speeds up the review process compared with the old process.
- RT2. The system makes reviewer decision steps clearer and faster.
- RT3. The system reduces delays in moving from submission to decision.
- RT4. The status updates help me respond quickly to pending actions.
- RT5. The system supports timely completion of portfolio review tasks.

---

## Section E. Governance and Traceability (GT)

- GT1. The access permissions in FPMS match user roles appropriately.
- GT2. The system records actions in a way that supports accountability.
- GT3. The system improves transparency of who submitted/reviewed/approved records.
- GT4. The reporting/export features support compliance and audit needs.
- GT5. The system helps management monitor portfolio progress at program level.

---

## Section F. System Usability Scale (SUS)

Instruction: Rate your agreement with each statement.

- SUS1. I think that I would like to use this system frequently.
- SUS2. I found the system unnecessarily complex.
- SUS3. I thought the system was easy to use.
- SUS4. I think that I would need the support of a technical person to use this system.
- SUS5. I found the various functions in this system were well integrated.
- SUS6. I thought there was too much inconsistency in this system.
- SUS7. I would imagine that most people would learn to use this system very quickly.
- SUS8. I found the system very cumbersome to use.
- SUS9. I felt very confident using the system.
- SUS10. I needed to learn a lot of things before I could get going with this system.

Note: Keep standard SUS wording for comparability.

---

## Section G. Technology Acceptance Model (TAM)

### G1. Perceived Usefulness (PU)
- PU1. Using FPMS improves my performance in portfolio-related tasks.
- PU2. Using FPMS increases my productivity in completing portfolio work.
- PU3. FPMS makes portfolio management more effective.
- PU4. FPMS helps me complete portfolio tasks more quickly.
- PU5. FPMS is useful for my role in academic compliance processes.
- PU6. Overall, FPMS enhances my work quality in portfolio tasks.

### G2. Perceived Ease of Use (PEOU)
- PEOU1. Learning to operate FPMS was easy for me.
- PEOU2. My interaction with FPMS is clear and understandable.
- PEOU3. I find FPMS easy to use.
- PEOU4. It is easy for me to become skillful at using FPMS.
- PEOU5. Navigating FPMS features is straightforward.
- PEOU6. Performing tasks in FPMS requires little mental effort.

### G3. Behavioral Intention to Use (BI)
- BI1. I intend to continue using FPMS in future portfolio cycles.
- BI2. I will recommend FPMS to colleagues involved in portfolio workflows.
- BI3. If available, FPMS would be my preferred platform for portfolio management.
- BI4. I am willing to rely on FPMS for compliance-related document processes.

---

## Section H. Open-Ended Questions (Optional but Recommended)

- OQ1. What FPMS feature helped you most in portfolio tasks?
- OQ2. What is the biggest challenge you experienced while using FPMS?
- OQ3. What improvements should be prioritized in the next version?

---

## Scoring and Analysis Guide

### 1. Construct Scores
Compute weighted mean and standard deviation per construct:
- Workflow Improvement (WI)
- Completeness Support (CS)
- Review Turnaround Support (RT)
- Governance and Traceability (GT)
- TAM: PU, PEOU, BI

Also compute grouped means aligned to Chapter I:
- `Problem 1 (Workflow Profile)` = mean(WI + RT items)
- `Problem 2 (Compliance and Governance Profile)` = mean(CS + GT items)
- `Problem 3 (Usability and Acceptance)` = SUS + TAM construct means

Interpretation note:
- Survey-based RT and GT scores represent user-perceived support and governance experience.
- Objective review-turnaround and action-level audit indicators should be reported from system logs only when corresponding review/audit records are available in the extraction window.

### 2. Positive Response Rate
For each construct:

Positive Response Rate = ((Agree + Strongly Agree) / Total Responses) x 100

### 3. SUS Scoring
Use standard SUS scoring:

1. For odd-numbered items (1,3,5,7,9): score contribution = response - 1
2. For even-numbered items (2,4,6,8,10): score contribution = 5 - response
3. Sum all contributions and multiply by 2.5
4. SUS overall score range: 0-100

### 4. Reliability
Compute Cronbach's alpha for each multi-item construct:
- WI, CS, RT, GT, PU, PEOU, BI
- SUS (optional, if required by adviser/panel)

---

## Suggested Interpretation Bands for Means

- 4.21-5.00: Strongly Agree (Highly Acceptable)
- 3.41-4.20: Agree (Acceptable)
- 2.61-3.40: Neutral (Moderately Acceptable)
- 1.81-2.60: Disagree (Slightly Acceptable)
- 1.00-1.80: Strongly Disagree (Not Acceptable)

---

## Administration Notes

1. Pilot test with 5-10 users before full rollout.
2. Revise ambiguous wording before final administration.
3. Secure consent and anonymize responses.
4. Keep a codebook for variable names and item mappings.
